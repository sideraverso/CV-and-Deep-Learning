{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Image Classification With A Deep Convolutional Neural Network (AlexNet)\n",
    "This notebook details the steps taken to implement and train a Deep Neural Network(DNN) on the [Cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset in order to perform the computer vision task of image classification on the Cifar-10 test dataset partition. \n",
    "\n",
    "To build, train and test a neural network, the libraries TensorFlow and Keras are leveraged to provide the features and methods required to build the components of a neural network. Supporting libraries such as Matplotlib and Numpy are utlised for visualisation and data processing\n",
    "\n",
    "**[TensorFlow](https://www.tensorflow.org/)**: An open-source platform for implementing, training, and deploying machine learning models.\n",
    "\n",
    "**[Keras](https://keras.io/)**: An open-source library used to implement neural network architectures that run on both CPUs and GPUs.\n",
    "\n",
    "**[Matplotlib](https://matplotlib.org/)**: Tool utilized to create visualization plots in Python such as charts, graphs and more"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cifar-10 Dataset\n",
    "\n",
    "The [Cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset consists of images of animals and everyday vehicles.\n",
    "The dataset was put together by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. More specifically, it contains 50,000 training examples and 10,000 testing examples, that are all color images with the dimension 32 x 32 categorized into 10 classes.\n",
    "\n",
    "[**Keras Dataset**](https://keras.io/api/datasets/) (keras.datasets)\n",
    "\n",
    "In the practical world of machine learning, obtaining dataset is costly in terms of time, money and effort.\n",
    "But a few introductory datasets have been collated together to help students and researchers build and analyse the performance of models on specifics datasets.\n",
    "Some of these dataset reside within the Keras API and are easily accessible through the [load_data()](https://keras.io/api/datasets/cifar10/#loaddata-function) method of each respective dataset.\n",
    "\n",
    "To load the Cifar-10 dataset: `keras.datasets.cifar10.load_data()`\n",
    "\n",
    "**Classes**\n",
    "| Label | Description |\n",
    "|-------|-------------|\n",
    "| 0     | airplane    |\n",
    "| 1     | automobile  |\n",
    "| 2     | bird        |\n",
    "| 3     | cat         |\n",
    "| 4     | deer        |\n",
    "| 5     | dog         |\n",
    "| 6     | frog        |\n",
    "| 7     | horse       |\n",
    "| 8     | ship        |\n",
    "| 9     | truck       |\n",
    "\n",
    "**Dataset Partitions**\n",
    "\n",
    "For this particular classification task, 45,000 training images, 10,000 test images, and 5,000 validation images are utilized.\n",
    "- Training Data: This is the group of our dataset used to train the neural network directly. Training data refers to the dataset partition exposed to the neural network during training.\n",
    "- Validation Data: This group of the dataset is utilized during training to assess the performance of the network at various iterations.\n",
    "- Test Data: This partition of the dataset evaluates the performance of our network after the completion of the training phase.\n",
    "\n",
    "**The code snippet below unpacks the tuple of numpy arrays that correspons to the training images and labels, as well as the testing images and labels**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CLASS_NAMES= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validation Data\n",
    "The validation partition of the dataset is obtained from taking a slice of the training data. More specifically, the first 5000 training images and labels are assigned to the validation data.\n",
    "The new training data is reassigned to every training data element but the first 5000 images in the original training data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "validation_images, validation_labels = train_images[:5000], train_labels[:5000]\n",
    "train_images, train_labels = train_images[5000:], train_labels[5000:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input Pipeline and TensorFlow Dataset\n",
    "\n",
    "Input pipelines are used as a method of streaming data to a model in an automated fashion. Input pipelines can be made responsible for the automation of preprocessing steps taken on input data before presented to the network during training.\n",
    "\n",
    "In this notebook we create input pipelines for our training, testing and validation data using the [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) API. With well constructed pipelines transformations and augmentation can be made to data points or batches of the dataset partitions in an memory efficient manner.\n",
    "\n",
    "The source of the data used to create the Dataset Object for our input pipeline is the numpy arrays of the dataset partitions created in the cells above. More specfically the `tf.data.Dataset.from_tensor_slices()` allows for the creation of the required Dataset object.\n",
    "\n",
    "Below we create the Dataset Objects `train_da`, `test_ds` and `validation_ds` which represent the input pipelines for the training, testing and validation data respectively."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualising Training Data\n",
    "\n",
    "The Dataset object returned tf.data.Dataset can be iterated over, so we can view a portion of the dataset using pyplot.\n",
    "\n",
    "Below is a visualisation of the first five images and corresponding labels."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i, (image, label) in enumerate(train_ds.take(5)):\n",
    "    ax = plt.subplot(5,5,i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(CLASS_NAMES[label.numpy()[0]])\n",
    "    plt.axis('off')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image Preproccessing\n",
    "\n",
    "**Standardization**\n",
    "The TensorFlow module [tf.image](https://www.tensorflow.org/api_docs/python/tf/image) provides a suite of processing and transformation functions that can be applied on image dataset, so resizing, recoloring, cropping and other common transformation become trivial. \n",
    "\n",
    "In this notebook the images are resized from the original dimensions of 32x32 to 227x227, this is because the input layer of the AlexNet architecture expects images of size 227x227. In addition to resizing, the images are normalized to have a mean of 0 and standard deviation of 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def image_preprocessing(image, label):\n",
    "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    # Resize images from 32x32 to 277x277\n",
    "    image = tf.image.resize(image, (227,227))\n",
    "    return image, label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "test_ds_size = tf.data.experimental.cardinality(test_ds).numpy()\n",
    "validation_ds_size = tf.data.experimental.cardinality(validation_ds).numpy()\n",
    "print(\"Training data size:\", train_ds_size)\n",
    "print(\"Test data size:\", test_ds_size)\n",
    "print(\"Validation data size:\", validation_ds_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finializing the Input pipelines\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_ds = (train_ds\n",
    "                  .map(image_preprocessing)\n",
    "                  .cache()\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "\n",
    "test_ds = (test_ds\n",
    "                  .map(image_preprocessing)\n",
    "                  .cache()\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "\n",
    "validation_ds = (validation_ds\n",
    "                  .map(image_preprocessing)\n",
    "                  .cache()\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "root_logdir = os.path.join(os.curdir, \"logs\\\\fit\\\\\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001), metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.fit(train_ds,\n",
    "          epochs=30,\n",
    "          validation_data=validation_ds,\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_cb])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.evaluate(test_ds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# AlexNet with Augmentation layers\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.experimental.preprocessing.RandomRotation(0.2, input_shape=(227,227,3)),\n",
    "    keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "    keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.01, momentum=0.9), metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          epochs=400,\n",
    "          validation_data=validation_ds,\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_cb])\n",
    "\n",
    "model.evaluate(test_ds)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('deepcourse': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "interpreter": {
   "hash": "dc00d3c18918e3d7b202c635280a2defd5a3767f6fcbbc54f3a1ab7d5490b6ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}